# Answer to jYdn

Dear Reviewer, Thank you so much for the feedback. I appreciate that you point out unclarities in our contributions or extension to climate systems. These are very valuable points and I will incorporate my responses to your questions into the text to help future readers get a better understanding of the paper. If you are willing to raise your score based on our clarifications below, we would greatly appreciate it.

It seems like your biggest questions is about the novelty of our work. And, I agree that there has recently been a lot of works in ML for learning parametrizations. Here, we are the first to propose neural operators (NOs) for learning parametrizations. As neural operators have started to gain a lot of attention we believe that it is important to ask: “what is the value of neural operators for learning parametrizations?”. We started this work in 2021, so to answer this question, we had to determine and understand appropriate PDE set-ups for benchmarking, define evaluation metrics, and run the experiments. Admittedly understanding and creating the PDE datasets took the longest time. 

I agree that non-local, flexible and resolution-independent is not our contribution but rather FNOs. In our paper we focus on clarifying the links between these NO properties and parametrizations: 

1) The property of learning non-local parametrizations is particularly useful for correcting global biases such as the demonstrated spectral error of QG turbulence or undemonstrated far-field climate phenomena, such as, mid-latitude fronts, squall lines, or long wave propagation. For capturing local phenomena CNN-based parametrizations might be a more suitable choice.
2) The resolution-independence, assuming a uniform grid, is important in climate science for sharing trained parametrizations across Earth system modeling experiments which are commonly run at 0.5°, 1° or 2° global resolution. 
3) We use flexible as a synonym for universality or adaptability of the method; maybe that would have been a more accurate word choice. We say a method is more “flexible” if the development time for transferring one method from one application to another application is shorter than for another method. Using NOs for parametrizations is more flexible than analytically derived parametrizations and our Multiscale Neural Operator (MNO) is more flexible than multigrid (Briggs et al., 2000), spectral methods (Boyd et al., 2013), or traditional surrogate models (Karniadakis et al., 2021) due to the need for less domain-specific adaptations. 

To your point, some of my above comments are not as clear in the submitted paper so I will adapt the paper text to clarify these contributions. 

Regarding your other questions:
- I would like to clarify that we are using MSE as a loss function and not a physics-informed loss according to (Raissi et al., 2019). We use a standard loss function to focus on a fair comparison between climatology, traditional polynomial, ML-based FCNN, and neural operator parametrizations. Using a physics-informed loss would be useful extension of our work as there exist equations to test physical-consistency for some parametrizations (Prakash et al., 2021).

-  Q 1.) The novelty is that we ask what the value neural operators for learning parametrizations is. The biggest challenge was determining and understanding appropriate PDE benchmarking set-ups to highlight the properties of learning operators for learning parametrizations.

- Q 2.) We started with the multiscale Lorenz96 and quasi-geostrophic turbulence equation, because benchmarking novel ML-methods for non-local parametrizations in fully coupled climate models is very challenging and has not been done yet. As a next step towards this goal, we are determining a set of atmospheric parametrizations for which both resolution-independence and non-locality is important. For example, vertical dry convective boundary layer parametrizations or horizontal parametrizations of squall lines (P. Wang et al., 2022), respectively. After this, we would need to extend the work to learning multiple instead of single atmospheric parametrizations, possibly learning from (M. Howland et al., 2022, https://doi.org/10.1029/2021MS002735). Lastly, we would extend the work from atmospheric models to fully coupled climate models and which will pose another set of challenges.

- Q 3.) Good catch. We use flexible as a synonym for universality or adaptability of the method. I didn’t define it in the text, so I will do that. 

- Q 4.) Good question. The benchmarked local parametrizations (climatology, traditional, and ML-based) have a computational cost of O(N) during inference time, because they are applied independently to each low-resolution grid point. That is faster than our MNO which has O(N log N) computational cost. The computational cost comes from calculating spatial correlations with the Fourier transform. The fully-resolved numerical solver has O(N^2). Interestingly, CNNs with a local filter could achieve O(N) runtime and still learn global parametrizations, but they would not be resolution-independent to the same degree that neural operators are. I will clarify the runtime of local parametrizations in the text, thank you.

- Q 5.) Thank you for pointing out that large eddy simulation has a maximum step size. To clarify, are you referring to the maximum step size before becoming instable? I am most interested in global climate simulations for which the resolution of the large-scale model is determined by a trade-off between computational cost and resolution-requirements of downstream climate impact models. I believe that some of the large-scale models are already instable if they are run at 1° / 100km resolution without parametrizations. I won’t be able to perform the study for this work. But, it would be interesting to see how far learning-based parametrizations could push the resolution in large-scale simulations before becoming instable.
