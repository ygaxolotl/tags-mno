# Answer to jfkV
Dear Reviewer, I really appreciate your constructive feedback around CNNs, runtime measurements, and some clarifications. Please see my clarifications below and I would greatly appreciate if you consider raising your score if my comments improve your opinion of our paper.

It seems most important to clarify the value of resolution independence and what we mean by “easy-to-share” parametrizations. In our case, an easy-to-share parametrization can be trained on one grid resolution, but applied during inference on other grid resolutions. The „ease to share“ parametrizations is an important requirement from Earth system modeling. For example, to create the well-known ensemble of climate models that is used for global policymaking, CMIP6, multiple research groups each develop their own climate model. The climate models of each groups differ slightly in the choice of parametrizations and grid resolution; usually 0.5°, 1°, or 2°. Currently all models use analytically-derived parametrizations. Developing alternative learning-based parametrizations would require significant computational cost and could likely only be performed by a select number of research groups. In order for the learning-based parametrization to still be adopted by other research groups it would need to be easy-to-share from the developer to the user groups. In this case, the parametrization would be easier to share if it can be trained on the developing group’s grid resolution and used by another group’s grid resolution. I will include this explanation in the paper.

We believe that it is important to ask and study the question: “what is the value of neural operators for learning parametrizations?”. I agree that our desire for clarity in the form of repeating the contributions might have overstressed this contribution. Especially, in the light that our work builds on other works in learning-based parametrizations and is similar to the great work in (Lapeyre, et al. 2019) by substituting CNNs with Neural Operators. However, quantifying the use of neural operators still took significant effort, particularly, in selecting, designing, and adapting code to implement a set of benchmark equations. A big challenge was that it was not possible to use the datasets of many ML-based parametrization works including (Lapeyre et al., 2019), because they have only published a dataset but omitted the data-generating solver.

Lastly, I agree that a comparison to resolution-independent CNNs (e.g., via up-/downscaling onto a fixed grid) is still interesting. I believe there is special value in evaluating how the locality bias of CNNs and the global spectral bias of neural operators could be combined to learn multiple parametrizations that are local and global in nature. For example, CNNs might be a better choice to represent single cells of deep convection whereas and neural operators might be a better choice to represent far-field phenomena, such as squall lines. A full comparison of CNNs vs. neural operators is beyond the scope of this conference paper, but I will aim to include such a comparison in a journal version of this paper. 

Regarding your other questions:
- Original question
  - Our answer
- The authors state that "MNO's explicit formulation increases interpretability and ease of incorporating symmetries and constraints. With FNO, we exploit approximate translational symmetries in the data and ...". I find this to be quite a generous description. I don't see how it is any easier or harder than with most other ML-based methods. Further the claim about translations is problematic in two ways: first, FNOs are not really translation symmetric unless you work on a torus (and there are other issues even then) + many problems that involve transport, convection, wave propagation, etc, over inhomogeneous coefficients are not translation equivariant so even if this were true it would be detrimental.
  - I would like to clarify. I am claiming that limiting learning to the parametrization term will allow researchers to incorporate known symmetrics and constraints of the parametrization term into the model. See for example (Prakash et al., 2021) for a great list of known symmetries of the subgrid stress parametrization term in large eddy simulations.
  - I claimed that FNO exploits „approximate translational symmetries“. I agree that they are not translation symmetric on a square domain. Your comment helps me see that my formulation was more misleading than helpful. I will remove the claim of „approximate translational symmetries“ and rewrite it to refer to the inductive biases of FNO. 
  - Lastly, I also believe that learning the parametrization of different phenomena will require different architecture choices. While neural operators might be better in capturing global correlations, such as the spectral error in QG turbulence or the long wave pattern of squall lines (P. Wang, 2022), CNNs might become a better choice for local correlations.  
- The complexity estimates do not take into account the number of layer and number of channels. Presumably those scale with some complexity parameter of the problem and they cannot be assumed to be O(1).
  - This is a very fair comment. MNO would scale by O(N log N * n_layers). As you are likely aware, it is unknown how the number of layers scales with data complexity in the case of neural operators. So, evaluating this runtime would require a significant amount of compute that we did not have available for this study. However, I will edit the text to clarify the scaling with number of layers. We would like to point that our runtime comparison goes beyond other runtime comparisons that focus on reporting an X-times increase in cost for a given resolution, similar to (Li Z., Fourier Neural Operator, 2021a). 
- Are you interested in the evolution of the filtered variable \bar{u} (as in (1)) or of u itself (as in (9))?
  - Good catch. There is an error in (9) and I will correct it. I am interested in the evolution of the filtered variable \bar{u} as in (1). 
- It would be very helpful to accompany (9) and the subsequent displayed equation by a figure.
  - I can understand how the equations in (9) are quite a lot. The existing Fig 3 – left displays equation (9) in the generalized form. Does this figure help clarify the equation? I forgot to reference it close to (9), so I will do that. Thank you. 
- What does it mean that a subgrid parameterization is "hard to share"? In what sense is an FNO "easy to share"?
  - see above
- Why is (8) called a PDE? There is only a time derivative.
  - Good catch. I will rename it into ODE. I called it PDE, because I initially believed that multiscale Lorenz96 was derived from a spatiotemporally continuous system. But, multiscale Lorenz96 has always been an ODE that is continous in time and discretized in space. 
- The method you propose involves two scales; is it then common to use the term "multiscale"?
  - Yes, I understand the confusion here. However, in some fields including Earth System Modeling is indeed common to use the word multiscale even when just referring to two scales. See, for example, (Pavliotis and Stuart, 2008), LBNL’s Multiscale project (https://multiscale.lbl.gov/), or the Nobel lecture on multiscale modeling in chemistry (https://doi.org/10.1002/anie.201403691).
